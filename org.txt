深度学习通过构建多层神经网络自动提取特征，在计算机视觉领域取得突破性进展。典型的卷积神经网络包含卷积层、池化层和全连接层。
Transformer模型摒弃了传统的循环神经网络结构，完全依赖自注意力机制处理序列数据。本研究提出基于对比学习的文本增强方法，通过生成语义相近的困难负样本提升模型鲁棒性。知识图谱通过三元组表示实体关系，支持语义搜索和智能问答。